{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 4 (WORKS but!)\n",
    "- if you change the url, it will replace the first folder\n",
    "- it will create folder \"images\" then put everything inside with numbered folder\n",
    "- it's good if we want to scrape current chapter until end (it will some point stopped by server because limited access though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from selectolax.parser import HTMLParser\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "USER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36 Edg/126.0.0.0\"\n",
    "BASE_URL = \"https://www.mgeko.cc\"\n",
    "\n",
    "@dataclass\n",
    "class Response:\n",
    "    body_html: HTMLParser\n",
    "    next_page: dict\n",
    "\n",
    "def create_image_directory(image_dir: str) -> None:\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "\n",
    "def download_image(img_url: str, image_dir: str, page_number: int) -> None:\n",
    "    headers = {\"User-Agent\": USER_AGENT}\n",
    "    try:\n",
    "        img_response = httpx.get(img_url, headers=headers)\n",
    "        img_response.raise_for_status()\n",
    "        img_alt = img_url.split(\"/\")[-1].split(\".\")[0]\n",
    "        page_dir = os.path.join(image_dir, f\"page{page_number}\")\n",
    "        create_image_directory(page_dir)\n",
    "        filename = f\"{img_alt}.jpg\"\n",
    "        with open(os.path.join(page_dir, filename), \"wb\") as f:\n",
    "            f.write(img_response.content)\n",
    "            print(f\"Image '{filename}' downloaded successfully to page{page_number} directory.\")\n",
    "    except httpx.RequestError as e:\n",
    "        print(f\"Failed to download image '{img_alt}.jpg': {e}\")\n",
    "\n",
    "def get_img(client: httpx.Client, url: str, image_dir: str, page_number: int) -> None:\n",
    "    headers = {\"User-Agent\": USER_AGENT}\n",
    "    try:\n",
    "        resp = client.get(url, headers=headers)\n",
    "        resp.raise_for_status()\n",
    "        html = HTMLParser(resp.text)\n",
    "        imgs = html.css(\"#chapter-reader img\")\n",
    "        img_urls = [i.attrs[\"src\"] for i in imgs]\n",
    "        for img_url in img_urls:\n",
    "            download_image(img_url, image_dir, page_number)\n",
    "    except httpx.RequestError as e:\n",
    "        print(f\"Failed to fetch images: {e}\")\n",
    "\n",
    "def get_next_page_url(html: HTMLParser) -> dict:\n",
    "    next_page = html.css_first(\"#save > a.nextchap\")\n",
    "    if next_page:\n",
    "        return {\"href\": next_page.attributes[\"href\"]}\n",
    "    return {\"href\": False}\n",
    "\n",
    "def get_pages(client: httpx.Client, url: str, image_dir: str, base_url: str, page_number: int = 1) -> None:\n",
    "    try:\n",
    "        response = client.get(url, headers={\"User-Agent\": USER_AGENT})\n",
    "        response.raise_for_status()\n",
    "        html = HTMLParser(response.text)\n",
    "        get_img(client, url, image_dir, page_number)\n",
    "        next_page_url = get_next_page_url(html)\n",
    "        if next_page_url[\"href\"]:\n",
    "            next_page_url = urljoin(base_url, next_page_url[\"href\"])\n",
    "            print(f\"Next page: {next_page_url}\")\n",
    "            get_pages(client, next_page_url, image_dir, base_url, page_number + 1)\n",
    "    except httpx.RequestError as e:\n",
    "        print(f\"Failed to fetch page: {e}\")\n",
    "\n",
    "def main() -> None:\n",
    "    url = \"https://www.mgeko.cc/reader/en/stuck-in-the-tower-chapter-61-eng-li/\"\n",
    "    image_dir = \"images\"\n",
    "    create_image_directory(image_dir)\n",
    "    client = httpx.Client()\n",
    "    get_pages(client, url, image_dir, BASE_URL)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 5\n",
    "- it doesn't exist it will create new folder on D:/manga using the name based on url\n",
    "- if it exist, then do nothing\n",
    "- it creates new subfolder for each chapter according to chapter number in url, WHETHER it exist or not (meaning replace by new file)\n",
    "- it lacks checking existing file instead replaces with a new one. It will consume data by redownload file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from selectolax.parser import HTMLParser\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "USER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36 Edg/126.0.0.0\"\n",
    "BASE_URL = \"https://www.mgeko.cc\"\n",
    "\n",
    "@dataclass\n",
    "class Response:\n",
    "    body_html: HTMLParser\n",
    "    next_page: dict\n",
    "\n",
    "# Will create new manga folder if doesn't exist \n",
    "# Will rename folder based on url\n",
    "def create_image_directory(image_dir: str) -> None:\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "\n",
    "# Will turn the list of image links (from get_img()) to a folder name corresponding to their chapter \n",
    "# Will rename folder chapter using url links (url) from def main()\n",
    "# Will Rename jpg file using url links (img_url) from def get_img()\n",
    "# Will save each jpg into their respective folder (image_dir)\n",
    "def download_image(img_url: str, image_dir: str, url: str, page_number: int) -> None:\n",
    "    headers = {\"User-Agent\": USER_AGENT}\n",
    "    try:\n",
    "        img_response = httpx.get(img_url, headers=headers)\n",
    "        img_response.raise_for_status()\n",
    "        img_alt = img_url.split(\"/\")[-1].split(\".\")[0]\n",
    "        chapter_number = url.split(\"/\")[-2].split(\"-chapter-\")[1].split(\"-\")[0]\n",
    "        page_dir = os.path.join(image_dir, f\"Chapter {chapter_number}\")\n",
    "        create_image_directory(page_dir)\n",
    "        filename = f\"{img_alt}.jpg\"\n",
    "        with open(os.path.join(page_dir, filename), \"wb\") as f:\n",
    "            f.write(img_response.content)\n",
    "            print(f\"Image '{filename}' downloaded successfully to Chapter {chapter_number} directory.\")\n",
    "    except httpx.RequestError as e:\n",
    "        print(f\"Failed to download image '{img_alt}.jpg': {e}\")\n",
    "\n",
    "def get_img(client: httpx.Client, url: str, image_dir: str, page_number: int) -> None:\n",
    "    headers = {\"User-Agent\": USER_AGENT}\n",
    "    try:\n",
    "        resp = client.get(url, headers=headers)\n",
    "        resp.raise_for_status()\n",
    "        html = HTMLParser(resp.text)\n",
    "        imgs = html.css(\"#chapter-reader img\")\n",
    "        img_urls = [i.attrs[\"src\"] for i in imgs]\n",
    "        for img_url in img_urls:\n",
    "            download_image(img_url, image_dir, url, page_number)\n",
    "    except httpx.RequestError as e:\n",
    "        print(f\"Failed to fetch images: {e}\")\n",
    "\n",
    "def get_next_page_url(html: HTMLParser) -> dict:\n",
    "    next_page = html.css_first(\"#save > a.nextchap\")\n",
    "    if next_page:\n",
    "        return {\"href\": next_page.attributes[\"href\"]}\n",
    "    return {\"href\": False}\n",
    "\n",
    "def get_pages(client: httpx.Client, url: str, image_dir: str, base_url: str, page_number: int = 1) -> None:\n",
    "    try:\n",
    "        response = client.get(url, headers={\"User-Agent\": USER_AGENT})\n",
    "        response.raise_for_status()\n",
    "        html = HTMLParser(response.text)\n",
    "        get_img(client, url, image_dir, page_number)\n",
    "        next_page_url = get_next_page_url(html)\n",
    "        if next_page_url[\"href\"]:\n",
    "            next_page_url = urljoin(base_url, next_page_url[\"href\"])\n",
    "            print(f\"Next page: {next_page_url}\")\n",
    "            get_pages(client, next_page_url, image_dir, base_url, page_number + 1)\n",
    "    except httpx.RequestError as e:\n",
    "        print(f\"Failed to fetch page: {e}\")\n",
    "\n",
    "def main() -> None:\n",
    "    url = \"https://www.mgeko.cc/reader/en/against-the-gods-reuploaded-chapter-2-eng-li/\"\n",
    "    # Current Working Directory\n",
    "    os.chdir(\"D:/manga\")\n",
    "    # Folder will be rename according to url\n",
    "    chapter_name = url.split(\"/\")[-2].split(\"-chapter-\")[0].replace(\"-\", \" \")\n",
    "    image_dir = chapter_name\n",
    "    # from previous define function to create main folder if doesn't exist\n",
    "    create_image_directory(image_dir)\n",
    "    client = httpx.Client()\n",
    "    get_pages(client, url, image_dir, BASE_URL)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THIS IS HOW THE FOLDER RENAME WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "against-the-gods-reuploaded-chapter-44-eng-li\n",
      "against-the-gods-reuploaded-chapter-44-eng-li\n",
      "against-the-gods-reuploaded\n",
      "against the gods reuploaded\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.mgeko.cc/reader/en/against-the-gods-reuploaded-chapter-44-eng-li/\"\n",
    "judul = url.split(\"/\")\n",
    "print(judul[5])\n",
    "print(judul[-2])\n",
    "print(judul[-2].split(\"-chapter-\")[0])\n",
    "print(judul[-2].split(\"-chapter-\")[0].replace(\"-\", \" \"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "against-the-gods-reuploaded-chapter-44-eng-li\n",
      "-44-eng-li\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.mgeko.cc/reader/en/against-the-gods-reuploaded-chapter-44-eng-li/\"\n",
    "chapter = url.split(\"/\")\n",
    "print(chapter[5])\n",
    "print(chapter[5].split(\"-chapter\")[1])\n",
    "print(chapter[5].split(\"-chapter-\")[1].split(\"-\")[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                      +---------------+\n",
    "                                      |  main()      |\n",
    "                                      +---------------+\n",
    "                                             |\n",
    "                                             |\n",
    "                                             v\n",
    "                                      +---------------+\n",
    "                                      |  Set URL,     |\n",
    "                                      |  image_dir,   |\n",
    "                                      |  and BASE_URL  |\n",
    "                                      +---------------+\n",
    "                                             |\n",
    "                                             |\n",
    "                                             v\n",
    "                                      +---------------+\n",
    "                                      |  create_image_directory  |\n",
    "                                      |  (create main folder)    |\n",
    "                                      +---------------+\n",
    "                                             |\n",
    "                                             |\n",
    "                                             v\n",
    "                                      +---------------+\n",
    "                                      |  get_pages()    |\n",
    "                                      |  (recursive function)  |\n",
    "                                      +---------------+\n",
    "                                             |\n",
    "                                             |\n",
    "                                             v\n",
    "                                      +---------------+\n",
    "                                      |  get_img()     |\n",
    "                                      |  (fetch images)    |\n",
    "                                      +---------------+\n",
    "                                             |\n",
    "                                             |\n",
    "                                             v\n",
    "                                      +---------------+\n",
    "                                      |  download_image  |\n",
    "                                      |  (download image)  |\n",
    "                                      +---------------+\n",
    "                                             |\n",
    "                                             |\n",
    "                                             v\n",
    "                                      +---------------+\n",
    "                                      |  get_next_page_url  |\n",
    "                                      |  (get next page URL)  |\n",
    "                                      +---------------+\n",
    "                                             |\n",
    "                                             |\n",
    "                                             v\n",
    "                                      +---------------+\n",
    "                                      |  get_pages()    |\n",
    "                                      |  (recursive call)  |\n",
    "                                      +---------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST DEBUGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from selectolax.parser import HTMLParser\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "USER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36 Edg/126.0.0.0\"\n",
    "BASE_URL = \"https://www.mgeko.cc\"\n",
    "\n",
    "@dataclass\n",
    "class Response:\n",
    "    body_html: HTMLParser\n",
    "    next_page: dict\n",
    "\n",
    "# Will create new manga folder if doesn't exist \n",
    "# Will rename folder based on url\n",
    "def create_image_directory(image_dir: str) -> None:\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "\n",
    "# Will turn the list of image links (from get_img()) to a folder name corresponding to their chapter \n",
    "# Will rename folder chapter using url links (url) from def main()\n",
    "# Will Rename jpg file using url links (img_url) from def get_img()\n",
    "# Will save each jpg into their respective folder (image_dir)\n",
    "def download_image(img_url: str, image_dir: str, url: str, page_number: int) -> None:\n",
    "    headers = {\"User-Agent\": USER_AGENT}\n",
    "    try:\n",
    "        img_response = httpx.get(img_url, headers=headers)\n",
    "        img_response.raise_for_status()\n",
    "        img_alt = img_url.split(\"/\")[-1].split(\".\")[0]\n",
    "        chapter_number = url.split(\"/\")[-2].split(\"-chapter-\")[1].split(\"-\")[0]\n",
    "        page_dir = os.path.join(image_dir, f\"Chapter {chapter_number}\")\n",
    "        create_image_directory(page_dir)\n",
    "        filename = f\"{img_alt}.jpg\"\n",
    "        with open(os.path.join(page_dir, filename), \"wb\") as f:\n",
    "            f.write(img_response.content)\n",
    "            print(f\"Image '{filename}' downloaded successfully to Chapter {chapter_number} directory.\")\n",
    "    except httpx.RequestError as e:\n",
    "        print(f\"Failed to download image '{img_alt}.jpg': {e}\")\n",
    "\n",
    "def get_img(client: httpx.Client, url: str, image_dir: str, page_number: int) -> None:\n",
    "    headers = {\"User-Agent\": USER_AGENT}\n",
    "    try:\n",
    "        resp = client.get(url, headers=headers)\n",
    "        resp.raise_for_status()\n",
    "        html = HTMLParser(resp.text)\n",
    "        imgs = html.css(\"#chapter-reader img\")\n",
    "        img_urls = [i.attrs[\"src\"] for i in imgs]\n",
    "        for img_url in img_urls:\n",
    "            download_image(img_url, image_dir, url, page_number)\n",
    "    except httpx.RequestError as e:\n",
    "        print(f\"Failed to fetch images: {e}\")\n",
    "\n",
    "def get_next_page_url(html: HTMLParser) -> dict:\n",
    "    next_page = html.css_first(\"#save > a.nextchap\")\n",
    "    if next_page:\n",
    "        return {\"href\": next_page.attributes[\"href\"]}\n",
    "    return {\"href\": False}\n",
    "\n",
    "def get_pages(client: httpx.Client, url: str, image_dir: str, base_url: str, page_number: int = 1) -> None:\n",
    "    try:\n",
    "        response = client.get(url, headers={\"User-Agent\": USER_AGENT})\n",
    "        response.raise_for_status()\n",
    "        html = HTMLParser(response.text)\n",
    "        get_img(client, url, image_dir, page_number)\n",
    "        next_page_url = get_next_page_url(html)\n",
    "        if next_page_url[\"href\"]:\n",
    "            next_page_url = urljoin(base_url, next_page_url[\"href\"])\n",
    "            print(f\"Next page: {next_page_url}\")\n",
    "            get_pages(client, next_page_url, image_dir, base_url, page_number + 1)\n",
    "    except httpx.RequestError as e:\n",
    "        print(f\"Failed to fetch page: {e}\")\n",
    "\n",
    "def main() -> None:\n",
    "    url = \"https://www.mgeko.cc/reader/en/against-the-gods-reuploaded-chapter-2-eng-li/\"\n",
    "    # Current Working Directory\n",
    "    os.chdir(\"D:/manga\")\n",
    "    # Folder will be rename according to url\n",
    "    chapter_name = url.split(\"/\")[-2].split(\"-chapter-\")[0].replace(\"-\", \" \")\n",
    "    image_dir = chapter_name\n",
    "    # from previous define function to create main folder if doesn't exist\n",
    "    create_image_directory(image_dir)\n",
    "    client = httpx.Client()\n",
    "    get_pages(client, url, image_dir, BASE_URL)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('condawind')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e3802b27887ce9c9a399d18b9e88e87d3bbd2cb82bdf3ac49206f060623ca27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
